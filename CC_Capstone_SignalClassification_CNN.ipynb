{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-task Convolutional Neural Network for Radio Frequency Signal Classification\n",
    "#Author: Chelsea Cook\n",
    "#Date: 12 December 2021\n",
    "\n",
    "#Data source: ANDRO Computational Solutions, LLC (2020). RadarCommDataset [Data set]. \n",
    "#GitHub. https://github.com/ANDROComputationalSolutions/RadarCommDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import sys\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import decimal\n",
    "import keras\n",
    "import plotly\n",
    "from sklearn import preprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Access dataset from file\n",
    "\n",
    "dkeys = []  # labels of each entry in the h5\n",
    "W = []      # dataset container\n",
    "Wq = []\n",
    "Wi = []\n",
    "\n",
    "with h5py.File(\"C:\\\\Users\\\\lason\\\\OneDrive\\\\Documents\\\\DSC CAPSTONE\\\\RadComDynamic\\\\RadComDynamic.hdf5\", 'r') as f:\n",
    "    for key in f.keys():\n",
    "        dkeys.append(key)\n",
    "        W.append(f[key][:])\n",
    "        #print(key)\n",
    "        #print('real', f[key][:128])\n",
    "        #print('imag', f[key][128:])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Break out values in dkeys to see each line of keys\n",
    "\n",
    "dkeys_2 = [ast.literal_eval(i) for i in dkeys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkeys_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put keys into dataframe with column headers\n",
    "\n",
    "dkeys_df = pd.DataFrame(dkeys_2, columns = ['Modulation', 'Signal_Type', 'SNR', 'Sample_Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dkeys_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#View keys\n",
    "dkeys_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at mean SNR values across modulation types to see how they are distributed\n",
    "\n",
    "dkeys_df.groupby(['Modulation'])['SNR'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at mean SNR values across signal types to see how they are distributed\n",
    "\n",
    "dkeys_df.groupby(['Signal_Type'])['SNR'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print variable types for keys\n",
    "\n",
    "dkeys_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Explore distribution of modulation categories\n",
    "\n",
    "dkeys_df[\"Modulation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore distribution of signal type categories\n",
    "\n",
    "dkeys_df[\"Signal_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print number of samples with each SNR value\n",
    "\n",
    "dkeys_df[\"SNR\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print number of times each sample value appears (total number of waveforms with 700 snapshots)\n",
    "\n",
    "dkeys_df[\"Sample_Value\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding type and shape of waveform data object (W)\n",
    "\n",
    "print(W[0])\n",
    "print(type(W))\n",
    "\n",
    "print(np.shape(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put waveform data (I/Q) into dataframe\n",
    "\n",
    "w_df = pd.DataFrame(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the dataframe\n",
    "\n",
    "w_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join keys to waveform (I/Q) data\n",
    "\n",
    "df_combined = pd.merge(dkeys_df, w_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_combined[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Train/Validation/Test sets by shuffling data first for random distribution of samples\n",
    "#Set seed to prevent variation in sets on subsequent compilation\n",
    "\n",
    "np.random.seed(74)\n",
    "df_shuffled = np.array(df_combined)\n",
    "np.random.shuffle(df_shuffled)\n",
    "# df_shuffled = pd.DataFrame(df_shuffled, columns = df_combined.columns)\n",
    "df_shuffled[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put this array back into a dataframe for easier separation of dependent and independent variables\n",
    "\n",
    "full_shuffled_df = pd.DataFrame(df_shuffled, columns = df_combined.columns)\n",
    "full_shuffled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recreate array of I/Q values to reshape for modeling\n",
    "\n",
    "IQ_separate = full_shuffled_df.iloc[: ,4:]\n",
    "IQ_separate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IQ_array = np.asarray(IQ_separate).astype(np.float32)\n",
    "IQ_array.ndim\n",
    "np.shape(IQ_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape and check dimensions of I/Q array for use in CNN modeling\n",
    "\n",
    "CNN_Tensors = IQ_array.reshape((125361,16,16,1))\n",
    "np.shape(CNN_Tensors)\n",
    "CNN_Tensors.ndim\n",
    "CNN_Tensors[0].ndim\n",
    "CNN_Tensors.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training, validation and test sets for each DV/IV by separating the variable, ensuring it is an array (for acceptance \n",
    "#in the models), and then splitting its contents 70/20/10\n",
    "\n",
    "#I/Q data (waveforms)\n",
    "\n",
    "IQData = CNN_Tensors\n",
    "\n",
    "IQ_train = IQData[:87753]\n",
    "IQ_val = IQData[87753:112825]\n",
    "IQ_test = IQData[112825:]\n",
    "\n",
    "#Modulation\n",
    "\n",
    "ModData = full_shuffled_df[\"Modulation\"]\n",
    "ModData_array = ModData.to_numpy()\n",
    "\n",
    "Mod_train = ModData_array[:87753]\n",
    "Mod_val = ModData_array[87753:112825]\n",
    "Mod_test = ModData_array[112825:]\n",
    "\n",
    "#Signal Type\n",
    "\n",
    "SigData = full_shuffled_df[\"Signal_Type\"]\n",
    "SigData_array = SigData.to_numpy()\n",
    "\n",
    "Sig_train = SigData_array[:87753]\n",
    "Sig_val = SigData_array[87753:112825]\n",
    "Sig_test = SigData_array[112825:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First single-task CNN\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(16,16,1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten output from convolutional layers to add dense classifier layers\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(6, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify modulation type using CNN; first, categorical data (modulation types) must be encoded\n",
    "\n",
    "Mod_train_dummies = pd.get_dummies(Mod_train).astype(np.float32)\n",
    "Mod_val_dummies = pd.get_dummies(Mod_val).astype(np.float32)\n",
    "print(Mod_train_dummies[:5])\n",
    "np.shape(Mod_train_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#Train model over 15 epochs\n",
    "\n",
    "history = model.fit(IQ_train, Mod_train_dummies, epochs=15, batch_size=64, validation_data=(IQ_val, Mod_val_dummies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize accuracy of modulation classification over epochs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.ylim((.45,.8))\n",
    "plt.title('Training and validation accuracy - Modulation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Chart demonstrates that accuracy on the validation data flattens out after 10 epochs and model begins to overfit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode signal type data\n",
    "Sig_train_dummies = pd.get_dummies(Sig_train).astype(np.float32)\n",
    "Sig_val_dummies = pd.get_dummies(Sig_val).astype(np.float32)\n",
    "\n",
    "print(Sig_train_dummies[:5])\n",
    "type(Sig_train_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model signal type in single-task CNN\n",
    "\n",
    "sigmodel = models.Sequential()\n",
    "sigmodel.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(16,16,1)))\n",
    "sigmodel.add(layers.MaxPooling2D((2,2)))\n",
    "sigmodel.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
    "\n",
    "sigmodel.add(layers.Flatten())\n",
    "sigmodel.add(layers.Dense(64, activation = 'relu'))\n",
    "sigmodel.add(layers.Dense(8, activation = 'softmax'))\n",
    "\n",
    "sigmodel.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "history2 = sigmodel.fit(IQ_train, Sig_train_dummies, epochs=15, batch_size=64, validation_data=(IQ_val, Sig_val_dummies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize accuracy of signal type classification over epochs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accy = history2.history['accuracy']\n",
    "val_accy = history2.history['val_accuracy']\n",
    "loss = history2.history['loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, accy, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_accy, 'b', label = 'Validation acc')\n",
    "plt.ylim((.45,.8))\n",
    "plt.title('Training and validation accuracy - Signal')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Chart demonstrates that accuracy on the validation data improves through ten epochs, then begins to decline and the model overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-task learning model (CNN) for both Modulation and Signal Classification\n",
    "\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "IQ_input = Input(shape=(16,16,1), dtype='float32')\n",
    "\n",
    "x = layers.Conv2D(64, (3,3), activation = 'relu')(IQ_input)\n",
    "x = layers.MaxPooling2D(2,2)(x)\n",
    "#x = layers.Conv2D(64, (3,3), activation = 'relu')(x)\n",
    "#x = layers.MaxPooling2D(2,2)(x)\n",
    "#x = layers.Flatten()(x)\n",
    "#x = layers.Dense(64, activation = 'relu')(x)\n",
    "\n",
    "mod_predict = layers.Conv2D(32, (3,3), activation = 'relu')(x)\n",
    "mod_predict = layers.Dropout(0.5)(mod_predict)\n",
    "mod_predict = layers.Flatten()(mod_predict)\n",
    "mod_predict = layers.Dense(256, activation = 'relu')(mod_predict)\n",
    "mod_predict = layers.Dense(6, activation = 'softmax', name = 'modtype')(mod_predict)\n",
    "\n",
    "sig_predict = layers.Conv2D(32, (3,3), activation = 'relu')(x)\n",
    "sig_predict = layers.Dropout(0.5)(sig_predict)\n",
    "sig_predict = layers.Flatten()(sig_predict)\n",
    "sig_predict = layers.Dense(256, activation = 'relu')(sig_predict)\n",
    "sig_predict = layers.Dense(8, activation = 'softmax', name = 'sigtype')(sig_predict)\n",
    "\n",
    "MTL = Model(IQ_input,\n",
    "               [mod_predict, sig_predict])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTL.compile(optimizer = 'adam', loss=['categorical_crossentropy', 'categorical_crossentropy'], loss_weights = [.2, .8], metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Predictions = MTL.fit(IQ_train, {'modtype': Mod_train_dummies, 'sigtype': Sig_train_dummies}, validation_data=(IQ_val, {'modtype': Mod_val_dummies, 'sigtype': Sig_val_dummies}), epochs = 30, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart training set accuracy against validation set accuracy (modulation first, then signal type)\n",
    "#Observe where validation accuracy peaks and overfitting become evident (train/val accuracy diverge)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "plt.clf()\n",
    "modchart = go.Figure()\n",
    "modchart.add_trace(go.Scatter(\n",
    "                        y=Predictions.history['modtype_accuracy'],\n",
    "                        name='Training'))\n",
    "modchart.add_trace(go.Scatter(\n",
    "                        y=Predictions.history['val_modtype_accuracy'],\n",
    "                        name='Validation'))\n",
    "\n",
    "modchart.update_layout(height=500,\n",
    "                      width=700,\n",
    "                      yaxis_range=[.5,.8],\n",
    "                      title='MTL Modulation Accuracy',\n",
    "                      xaxis_title='Epoch',\n",
    "                      yaxis_title='Accuracy')\n",
    "\n",
    "modchart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "sigchart = go.Figure()\n",
    "sigchart.add_trace(go.Scatter(\n",
    "                        y=Predictions.history['sigtype_accuracy'],\n",
    "                        name='Training'))\n",
    "sigchart.add_trace(go.Scatter(\n",
    "                        y=Predictions.history['val_sigtype_accuracy'],\n",
    "                        name='Validation'))\n",
    "\n",
    "sigchart.update_layout(height=500,\n",
    "                      width=700,\n",
    "                      yaxis_range=[.5,.8],\n",
    "                      title='MTL Signal Type Accuracy',\n",
    "                      xaxis_title='Epoch',\n",
    "                      yaxis_title='Accuracy')\n",
    "\n",
    "sigchart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predicted values for Modulation and Signal Type to compare to actual values and plot accuracy by SNR\n",
    "#Predictions are returned as probabilities for each class, must encode so that the positive class is 1 and remainder are 0\n",
    "#Convert encoded prediction values to class names and match against actuals, calculate prediction accuracy by SNR\n",
    "\n",
    "MTL_predict= MTL.predict(IQ_train)\n",
    "lb_sig = preprocessing.LabelBinarizer()\n",
    "lb_mod = preprocessing.LabelBinarizer()\n",
    "\n",
    "modlabels = np.argmax(MTL_predict[0], axis=-1)\n",
    "bin_modlabels = lb_mod.fit_transform(modlabels)\n",
    "\n",
    "siglabels = np.argmax(MTL_predict[1], axis=-1)\n",
    "bin_siglabels = lb_sig.fit_transform(siglabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat modulation predictions into dummies dataframe\n",
    "\n",
    "mod_predictions = pd.DataFrame(bin_modlabels, columns=Mod_train_dummies.columns)\n",
    "print(mod_predictions[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat signal predictions into dummies dataframe\n",
    "\n",
    "sig_predictions = pd.DataFrame(bin_siglabels, columns=Sig_train_dummies.columns)\n",
    "print(sig_predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collapse binary labels into class names\n",
    "\n",
    "collapsed_mod_predictions = mod_predictions.idxmax(axis=1)\n",
    "print(collapsed_mod_predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_sig_predictions = sig_predictions.idxmax(axis=1)\n",
    "print(collapsed_sig_predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the actual modulation and signal classes, as well as SNR, from the training dataset\n",
    "\n",
    "Subset_df = full_shuffled_df[[\"Modulation\",\"Signal_Type\",\"SNR\",\"Sample_Value\"]]\n",
    "print(Subset_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create combined dataframe with the predicted classes\n",
    "\n",
    "Add_mod = pd.merge(Subset_df, collapsed_mod_predictions.rename('Mod_Predictions'), left_index=True, right_index=True)\n",
    "\n",
    "Compare_df = pd.merge(Add_mod, collapsed_sig_predictions.rename('Sig_Predictions'), left_index=True, right_index=True)\n",
    "print(Compare_df.head())\n",
    "\n",
    "print(len(Compare_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tables of prediction accuracy at each SNR, including SNR, number of correct predictions, total observations, and % accuracy\n",
    "\n",
    "SNR_values = Compare_df.SNR.value_counts()\n",
    "SNR_values.index\n",
    "\n",
    "mod_acc_list = []\n",
    "sig_acc_list = []\n",
    "\n",
    "for snr in SNR_values.index:\n",
    "    counter_mod = 0\n",
    "    counter_sig = 0\n",
    "    temp_df = Compare_df[Compare_df['SNR']==snr].reset_index(drop=True)\n",
    "    for x in range(temp_df.shape[0]):\n",
    "        if temp_df['Modulation'][x] == temp_df['Mod_Predictions'][x]:\n",
    "            counter_mod+=1\n",
    "        if temp_df['Signal_Type'][x] == temp_df['Sig_Predictions'][x]:\n",
    "            counter_sig+=1\n",
    "    mod_snr_result = counter_mod/Compare_df[Compare_df['SNR']==snr].shape[0]\n",
    "    sig_snr_result = counter_sig/Compare_df[Compare_df['SNR']==snr].shape[0]\n",
    "    mod_acc_list.append([snr, mod_snr_result, counter_mod, Compare_df[Compare_df['SNR']==snr].shape[0]])\n",
    "    sig_acc_list.append([snr, sig_snr_result, counter_sig, Compare_df[Compare_df['SNR']==snr].shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create chart of modulation accuracy by SNR as dataframe and print in order from low to high SNR\n",
    "mod_acc_list\n",
    "\n",
    "mod_acc_df = pd.DataFrame(mod_acc_list, columns = ['SNR', 'Accuracy', 'Match', 'Total_Rows'])\n",
    "sig_acc_df = pd.DataFrame(sig_acc_list, columns = ['SNR', 'Accuracy', 'Match', 'Total_Rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_acc_by_snr = mod_acc_df.sort_values(\"SNR\", ascending=True)\n",
    "mod_acc_by_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create same chart for signal type\n",
    "\n",
    "sig_acc_by_snr = sig_acc_df.sort_values(\"SNR\", ascending=True)\n",
    "sig_acc_by_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot modulation and signal accuracy on training data by SNR\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "mod_acc_by_snr.plot(kind='line',x='SNR',y='Accuracy', ax=ax)\n",
    "plt.title('Modulation Accuracy by SNR')\n",
    "plt.xlabel('SNR')\n",
    "plt.ylabel('Modulation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart for signal type\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "sig_acc_by_snr.plot(kind='line',x='SNR',y='Accuracy', ax=ax)\n",
    "plt.title('Signal Accuracy by SNR')\n",
    "plt.xlabel('SNR')\n",
    "plt.ylabel('Signal Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test final MTL model on Test dataset\n",
    "#Use time to print how long it takes to predict\n",
    "\n",
    "#First, encode testdata\n",
    "Mod_test_dummies = pd.get_dummies(Mod_test).astype(np.float32)\n",
    "Sig_test_dummies = pd.get_dummies(Sig_test).astype(np.float32)\n",
    "\n",
    "tic=time.perf_counter()\n",
    "TestSetPredictions = MTL.evaluate(IQ_test, {'modtype': Mod_test_dummies, 'sigtype': Sig_test_dummies})\n",
    "toc=time.perf_counter()\n",
    "print(f\"Predicted 25,072 values in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predicted values for Modulation and Signal Type to compare to actual values and plot accuracy by SNR\n",
    "#Predictions are returned as probabilities for each class, must encode so that the positive class is 1 and remainder are 0\n",
    "#Convert encoded prediction values to class names and match against actuals, calculate prediction accuracy by SNR\n",
    "\n",
    "MTL_predict_test= MTL.predict(IQ_test)\n",
    "lb_sig1 = preprocessing.LabelBinarizer()\n",
    "lb_mod1 = preprocessing.LabelBinarizer()\n",
    "\n",
    "modtestlabels = np.argmax(MTL_predict_test[0], axis=-1)\n",
    "bin_modtestlabels = lb_mod1.fit_transform(modtestlabels)\n",
    "\n",
    "sigtestlabels = np.argmax(MTL_predict_test[1], axis=-1)\n",
    "bin_sigtestlabels = lb_sig1.fit_transform(sigtestlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat modulation predictions into dummies dataframe\n",
    "\n",
    "mod_test_predictions = pd.DataFrame(bin_modtestlabels, columns=Mod_test_dummies.columns)\n",
    "print(mod_test_predictions[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat signal predictions into dummies dataframe\n",
    "\n",
    "sig_test_predictions = pd.DataFrame(bin_sigtestlabels, columns=Sig_test_dummies.columns)\n",
    "print(sig_test_predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collapse binary labels into class names\n",
    "\n",
    "collapsed_mod_test_predictions = mod_test_predictions.idxmax(axis=1)\n",
    "print(collapsed_mod_test_predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_sig_test_predictions = sig_test_predictions.idxmax(axis=1)\n",
    "print(collapsed_sig_test_predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Subset_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(collapsed_mod_test_predictions))\n",
    "print(collapsed_mod_test_predictions.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join test predictions with test portion of dataset to compare for accuracy \n",
    "\n",
    "Test_Subset_df = Subset_df[112825:]\n",
    "Reset=Test_Subset_df.reset_index(drop=True)\n",
    "\n",
    "Add_test_mod = pd.merge(Reset, collapsed_mod_test_predictions.rename('Mod_Test_Predictions'), left_index=True, right_index=True)\n",
    "\n",
    "Final_Predictions_df = pd.merge(Add_test_mod, collapsed_sig_test_predictions.rename('Sig_Test_Predictions'), left_index=True, right_index=True)\n",
    "print(Final_Predictions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_final_values = Final_Predictions_df.SNR.value_counts()\n",
    "SNR_final_values.index\n",
    "\n",
    "mod_accy_list = []\n",
    "sig_accy_list = []\n",
    "\n",
    "for snr1 in SNR_final_values.index:\n",
    "    counter_mod1 = 0\n",
    "    counter_sig1 = 0\n",
    "    temp_df1 = Final_Predictions_df[Final_Predictions_df['SNR']==snr1].reset_index(drop=True)\n",
    "    for x in range(temp_df1.shape[0]):\n",
    "        if temp_df1['Modulation'][x] == temp_df1['Mod_Test_Predictions'][x]:\n",
    "            counter_mod1+=1\n",
    "        if temp_df1['Signal_Type'][x] == temp_df1['Sig_Test_Predictions'][x]:\n",
    "            counter_sig1+=1\n",
    "    mod_snr_results = counter_mod1/Final_Predictions_df[Final_Predictions_df['SNR']==snr1].shape[0]\n",
    "    sig_snr_results = counter_sig1/Final_Predictions_df[Final_Predictions_df['SNR']==snr1].shape[0]\n",
    "    mod_accy_list.append([snr1, mod_snr_results, counter_mod1, Final_Predictions_df[Final_Predictions_df['SNR']==snr1].shape[0]])\n",
    "    sig_accy_list.append([snr1, sig_snr_results, counter_sig1, Final_Predictions_df[Final_Predictions_df['SNR']==snr1].shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_accy_df = pd.DataFrame(mod_accy_list, columns = ['SNR', 'Accuracy', 'Match', 'Total_Rows'])\n",
    "sig_accy_df = pd.DataFrame(sig_accy_list, columns = ['SNR', 'Accuracy', 'Match', 'Total_Rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_accy_by_snr = mod_accy_df.sort_values(\"SNR\", ascending=True)\n",
    "mod_accy_by_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_accy_by_snr = sig_accy_df.sort_values(\"SNR\", ascending=True)\n",
    "sig_accy_by_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart accuracy by SNR\n",
    "\n",
    "xm=mod_accy_by_snr['SNR']\n",
    "ym=mod_accy_by_snr['Accuracy']\n",
    "xs=sig_accy_by_snr['SNR']\n",
    "ys=sig_accy_by_snr['Accuracy']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(xm,ym, label='Modulation')\n",
    "ax.plot(xs,ys, label='Signal Type')\n",
    "ax.legend(loc = 'lower right')\n",
    "plt.title('Modulation & Signal Prediction Accuracy by SNR')\n",
    "plt.xlabel('SNR')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code provided by ANDRO in GitHub to view/print the waveform images\n",
    "\n",
    "def parse_args():\n",
    "    \"Parse the command line arguments\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-num\", type=int,default=\"0\",\n",
    "                        help=\"Which sample to pick. 0 to 699\")\n",
    "    parser.add_argument(\"-snr\", type=int,default=\"-10\",\n",
    "                        help=\"SNR: -20 to 18 in 2 step increments\")\n",
    "    parser.add_argument(\"-mod\",default=\"amdsb\",\n",
    "                        help=\"Modulation options: pulsed,fmcw,bpsk,amdsb,amssb,ask\")\n",
    "    parser.add_argument(\"-sig\",default=\"AM radio\",\n",
    "                        help=\"Signal type options: Airborne-detection,Airborne-range,Air-Ground-MTI,Ground mapping,Radar-Altimeter,Satcom,AM radio,short-range\")\n",
    "    return parser.parse_known_args()\n",
    "#     return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args, unknown = parse_args()\n",
    "#     args = parse_args()\n",
    "    with h5py.File('C:\\\\Users\\\\lason\\\\OneDrive\\\\Documents\\\\DSC CAPSTONE\\\\RadComDynamic\\\\RadComDynamic.hdf5', 'r') as f:\n",
    "        key = args.mod,args.sig,args.snr,args.num \n",
    "        waveform = f[str(key)][:]\n",
    "        real = waveform[0:128]\n",
    "        imag = waveform[128:]\n",
    "    f.close()\n",
    "   \n",
    "    # Plot and visualize the selected sample\n",
    "    plt.figure(figsize=[8, 6])\n",
    "    plt.plot(real,'-go')\n",
    "    plt.plot(imag,'-bo')\n",
    "    plt.title(str(key), fontsize=16)\n",
    "    plt.show()\n",
    "if __name__ == \"__main__\":\n",
    "    print('Stop')\n",
    "    sys.exit(not main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way to print the waveform image\n",
    "\n",
    "for idx, val in enumerate(dkeys):\n",
    "    real = W[idx][0:128]\n",
    "    imag = W[idx][128:]\n",
    "    \n",
    "    plt.figure(figsize=[8, 6])\n",
    "    plt.plot(real,'-go')\n",
    "    plt.plot(imag,'-bo')\n",
    "    plt.title(val, fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
